# CHAPTER 35: Falsification, Evidence, and When to Walk Away

## The Scientific Discipline

Pattern work requires scientific rigor. Not everything that seems like a pattern is one. Not every pattern that works in one domain works in another. This chapter establishes standards for evidence, criteria for falsification, and the wisdom to abandon failed patterns.

## What Makes Evidence Good?

### The Evidence Hierarchy

**Level 1 - Anecdotal**:
- Single observations
- Personal experience
- Case reports
- Suggestive but not conclusive

**Level 2 - Observational**:
- Multiple cases
- Correlation studies
- Natural experiments
- Pattern recognition

**Level 3 - Quasi-Experimental**:
- Before-after studies
- Matched comparisons
- Interrupted time series
- Stronger causality

**Level 4 - Experimental**:
- Randomized controlled trials
- Laboratory studies
- Controlled variables
- Clear causality

**Level 5 - Systematic**:
- Meta-analyses
- Systematic reviews
- Multiple confirmations
- Robust evidence

### Quality Criteria

Strong evidence has:
- **Repeatability**: Others get same results
- **Consistency**: Works across contexts
- **Specificity**: Clear cause-effect
- **Temporality**: Cause precedes effect
- **Gradient**: Dose-response relationship
- **Plausibility**: Mechanism makes sense
- **Coherence**: Fits other knowledge

## The Falsification Framework

### What Would Prove This Wrong?

Every pattern claim must specify:

**Failure Conditions**:
- "If X happens, pattern doesn't work"
- "If Y absent, pattern fails"
- "If Z measurement, abandon pattern"

**Time Bounds**:
- "Should see effect within..."
- "If no change by..."
- "Maximum implementation period..."

**Success Metrics**:
- Specific, measurable outcomes
- Clear thresholds
- Objective assessment
- Multiple indicators

### Red Lines and Stop Rules

Pre-commit to stopping if:

**Harm Thresholds**:
- Unacceptable side effects
- Collateral damage exceeds benefits
- Vulnerable populations harmed
- Rights violations occur

**Failure Indicators**:
- No progress toward goals
- Opposite effects occurring
- Costs exceeding projections
- Stakeholder revolt

**Better Alternatives**:
- New evidence emerges
- Superior pattern found
- Circumstances change
- Assumptions violated

## Common Validity Threats

### Confirmation Bias

We see patterns everywhere:
- Cherry-picking supportive cases
- Ignoring contradictory evidence
- Post-hoc reasoning
- Texas sharpshooter fallacy

**Protection**: Pre-register hypotheses, seek disconfirmation

### Survivorship Bias

We only see successes:
- Failed patterns forgotten
- Success stories amplified
- Dead organisms don't report
- Bankrupt companies silent

**Protection**: Actively seek failures, study entire populations

### Scale Validity

Pattern may work but not scale:
- Works in lab, not field
- Works small, not large
- Works short-term, not long-term
- Works here, not there

**Protection**: Test at multiple scales, gradual expansion

### Context Validity

Pattern may be context-dependent:
- Cultural specificity
- Resource requirements
- Historical moment
- Enabling conditions

**Protection**: Multi-site testing, specify boundary conditions

## The Experimental Mindset

### Natural Experiments

Reality provides tests:
- Different policies in similar places
- Same policy, different times
- Unexpected shocks
- Historical comparisons

**Example**: COVID responses across countries
- Similar nations, different approaches
- Natural control groups
- Real-world outcomes
- Lessons learned

### Designed Experiments

Intentional testing:
- Pilot programs
- A/B testing
- Randomized trials
- Controlled studies

**Example**: Cash transfer programs
- Random village selection
- Control group comparison
- Long-term follow-up
- Clear outcomes

### Learning from Failure

Failed patterns teach:
- Why didn't it work?
- What assumptions were wrong?
- What context was missing?
- What pattern might work instead?

## When to Walk Away

### The Sunk Cost Trap

Previous investment doesn't justify continuation:
- Money already spent is gone
- Time invested won't return
- Reputation damage happens either way
- Future costs matter more than past

### Signs It's Time to Stop

**Pattern-Specific Failure**:
- Not achieving stated goals
- Creating more problems than solving
- Requiring ever-increasing resources
- Losing stakeholder support

**Context Change**:
- Original problem solved
- New problems more pressing
- Environment fundamentally different
- Better solutions available

**Evidence Evolution**:
- Initial evidence disproven
- Mechanisms don't work as thought
- Unacceptable externalities discovered
- Harm exceeds benefits

### The Graceful Exit

How to stop well:
1. **Acknowledge**: Admit pattern isn't working
2. **Analyze**: Understand why it failed
3. **Communicate**: Explain to stakeholders
4. **Transition**: Plan orderly winddown
5. **Document**: Record lessons learned
6. **Apply**: Use learning going forward

## The Negative Results Problem

### Why Negative Results Matter

Failed patterns teach us:
- What doesn't work
- Where boundaries are
- Which assumptions fail
- How to improve

### Publishing Failures

Create culture of:
- Failure repositories
- Negative result journals
- Post-mortem culture
- Learning celebrations

### The Graveyard

Maintain record of:
- Abandoned patterns
- Why they failed
- Lessons learned
- Conditions for resurrection

## Case Studies

### Success: Handwashing in Hospitals
- Semmelweis's observation (1847)
- Initial rejection
- Mechanism discovered (germs)
- Evidence accumulated
- Now universal practice
- Lesson: Evidence eventually wins

### Failure: Bleeding as Medicine
- Thousands of years of practice
- Theoretical justification (humors)
- High-status endorsement
- Finally tested properly
- Shown harmful
- Lesson: Longevity â‰  validity

### Walking Away: Hormone Replacement Therapy
- Observational studies promising
- Widely adopted
- RCT showed harm
- Practice changed rapidly
- Lives saved by stopping
- Lesson: Update with evidence

## The Meta-Evidence

### Does Pattern Transfer Work?

Evidence for this book's approach:
- **Supporting**: Cross-scale similarities, successful transfers, mechanistic explanations
- **Challenging**: Context specificity, scale transformations, human uniqueness
- **Verdict**: Cautious optimism with rigorous testing

### Falsification Criteria

This framework fails if:
- Patterns consistently don't transfer
- Mechanisms fundamentally different
- Human systems truly unique
- Harm exceeds benefits
- Better frameworks emerge

## Building Evidence Culture

### Organizational Practices

**Before Implementation**:
- Evidence review
- Falsification criteria
- Stop rules
- Measurement plan

**During Implementation**:
- Continuous monitoring
- Regular reviews
- Adjustment protocols
- Documentation

**After Implementation**:
- Honest evaluation
- Lesson extraction
- Knowledge sharing
- Method improvement

### Personal Practices

**Intellectual Honesty**:
- Admit uncertainty
- Seek disconfirmation
- Change with evidence
- Learn from failure

**Experimental Attitude**:
- Try things
- Measure results
- Adjust approach
- Share learning

## ðŸ§° Practice Prompt

Design a falsification test:
1. State your pattern hypothesis
2. What would prove it wrong?
3. How will you measure success?
4. Set a timeline for assessment
5. Define stop conditions
6. Plan data collection
7. Pre-commit to honesty

Remember: Strong patterns survive scrutiny; weak patterns deserve abandonment.